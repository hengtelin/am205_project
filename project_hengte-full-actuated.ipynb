{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array, sin, cos, dot, random, zeros, ones, exp\n",
    "from scipy.optimize import minimize, root\n",
    "from scipy.linalg import solve, norm\n",
    "from scipy.integrate import simps\n",
    "from scipy.interpolate import lagrange\n",
    "from math import pi\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation,rc\n",
    "%matplotlib inline\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from control import lqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanical System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change here\n",
    "#------------\n",
    "Duration = 3;\n",
    "FPS = 1000;\n",
    "starting_point = array([pi-0.1,0,0,0])\n",
    "target_point = array([pi,0,0,0])\n",
    "print_L = False\n",
    "global_B = array([[1,0],[0,1]])#full actuated\n",
    "global_B_dict={\"full\":array([[1,0],[0,1]]), \"under\": array([[0,0],[0,1]])}\n",
    "#-----------\n",
    "dt = 1./FPS\n",
    "N = int(Duration*FPS);\n",
    "friction = 2\n",
    "g = 9.8\n",
    "\n",
    "costs=[]\n",
    "\n",
    "def acrobot_gradient(x, u):\n",
    "    \n",
    "    M = array([[3 + 2*cos(x[1]), 1+cos(x[1])],[1+cos(x[1]), 1]])\n",
    "    c1 = x[3]*(2*x[2]+x[3])*sin(x[1]) - 2*g*sin(x[0]) - g*sin(x[0]+x[1])\n",
    "    c2 = -x[2]**2*sin(x[1]) - g*sin(x[0]+x[1])\n",
    "    a = np.concatenate([x[2:4], solve(M,array([c1-friction*x[2], c2-friction*x[3]]))])\n",
    "    bottom=solve(M,global_B)\n",
    "    B = array([[0,0],\n",
    "               [0,0],\n",
    "               [bottom[0,0],bottom[0,1]],\n",
    "               [bottom[1,0],bottom[1,1]]])\n",
    "    #print(u.shape)\n",
    "    xd = a + dot(B,u)\n",
    "    return xd\n",
    "    \n",
    "def acrobot_next_step(x,u):\n",
    "    \n",
    "    xd = acrobot_gradient(x,u)\n",
    "    new_x = x + xd*dt\n",
    "    #limit angle range to [0, 2pi]\n",
    "    #new_x[0]=new_x[0]%(2*pi)\n",
    "    #new_x[1]=new_x[1]%(2*pi)\n",
    "    #avoid acceleration overflow\n",
    "    return new_x#np.clip(new_x,-100000,100000)\n",
    "\n",
    "r=0.01\n",
    "k=1\n",
    "last_steps_bonus = 100\n",
    "penalize_u1_factor = 1\n",
    "def cost_function(x,u,i,n) : \n",
    "    if i >= (n-3):\n",
    "        return r/2*(penalize_u1_factor*u[0]**2+u[1]**2) + 1 - last_steps_bonus*exp(-k*cos(x[0]) + k*cos(x[1])-2*k)\n",
    "    else:\n",
    "        return r/2*(penalize_u1_factor*u[0]**2+u[1]**2) + 1 - exp(-k*cos(x[0]) + k*cos(x[1])-2*k) \n",
    "\n",
    "\n",
    "#define partial derivation functions\n",
    "def numerical_dfdxT(x,u):\n",
    "    delta = 0.0001\n",
    "    out = zeros([4,4])\n",
    "    for i in range(4):\n",
    "        delta_v = zeros(4)\n",
    "        delta_v[i] = delta\n",
    "        #print(x+delta_v)\n",
    "        out[i] = ((acrobot_gradient(x+delta_v,u)-acrobot_gradient(x-delta_v,u))*dt+2*delta_v)/2/delta\n",
    "    return out\n",
    "\n",
    "def df_ddx(x,u):\n",
    "    M = array([[3 + 2*cos(x[1]), 1+cos(x[1])],\n",
    "               [1+cos(x[1]),    1]\n",
    "              ])\n",
    "    C = array([[-2*sin(x[1])*x[3], -sin(x[1])*x[3]],\n",
    "               [sin(x[1])*x[2],    0]\n",
    "              ])\n",
    "    dGdq = array([[g*(2*cos(x[0])+cos(x[0]+x[1])),g*cos(x[0]+x[1])],\n",
    "                  [g*cos(x[0]+x[1]),              g*cos(x[0]+x[1])]\n",
    "                 ])\n",
    "    bottom_left = - solve(M,dGdq)\n",
    "    bottom_right = - solve(M,C+np.identity(2)*friction)\n",
    "    xd= array([[0,0,1,0],\n",
    "                  [0,0,0,1],\n",
    "                  [bottom_left[0,0],bottom_left[0,1],bottom_right[0,0],bottom_right[0,1]],\n",
    "                  [bottom_left[1,0],bottom_left[1,1],bottom_right[1,0],bottom_right[1,1]]\n",
    "                 ])\n",
    "    return xd\n",
    "\n",
    "def dfdxT(x,u):\n",
    "    xd = df_ddx(x,u)\n",
    "    x = xd*dt+np.identity(4)\n",
    "    return x.T\n",
    "\n",
    "def df_ddu(x,u):\n",
    "    M = array([[3 + 2*cos(x[1]), 1+cos(x[1])],[1+cos(x[1]), 1]])\n",
    "    bottom=solve(M,global_B)\n",
    "    B = array([[0,0],\n",
    "               [0,0],\n",
    "               [bottom[0,0],bottom[0,1]],\n",
    "               [bottom[1,0],bottom[1,1]]])\n",
    "    return B\n",
    "\n",
    "def dfdu(x,u):\n",
    "    return dt*df_ddu(x,u)\n",
    "\n",
    "\n",
    "def dgdx(x,u,i,n):\n",
    "    out = zeros(4)\n",
    "    x1= x[0]\n",
    "    x2= x[1]\n",
    "    out[0] = -exp(-k*cos(x1)+k*cos(x2)-2*k)*k*sin(x1)\n",
    "    out[1] = exp(-k*cos(x1)+k*cos(x2)-2*k)*k*sin(x2)\n",
    "    \n",
    "    if i >= (n-3):\n",
    "        out *= last_steps_bonus\n",
    "    return out\n",
    "def dgdu(x,u):\n",
    "    return r*array([u[0]*penalize_u1_factor,u[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearized System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def acrobot_linearized_system(relative_x=array([pi,0,0,0]), relative_u=0):\n",
    "    A = df_ddx(relative_x, relative_u)\n",
    "    B = df_ddu(relative_x, relative_u)\n",
    "    return (A,B)\n",
    "    \n",
    "def linearized_cost_function_matrices(relative_x=array([pi,0,0,0]), relative_u=0):\n",
    "    Q=array([[0.1*dt,0,0,0],[0,0.1*dt,0,0],[0,0,0,0],[0,0,0,0]])\n",
    "    Qf = 10*Q\n",
    "    R=array([[dt,0],[0,dt]])\n",
    "    return (Q,R,Qf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import solve_continuous_are\n",
    "\n",
    "def our_lqr(A,B,Q,R):    \n",
    "    P = solve_continuous_are(A,B,Q,R)\n",
    "    K = solve(R,dot(B.T,P))\n",
    "    return K\n",
    "\n",
    "def cost(x,u,Q,R):\n",
    "    return dot((x-target_point),dot(Q,(x-target_point)))*dot(u,dot(R,u))\n",
    "\n",
    "def end_cost(x,u,Qf):\n",
    "    return dot((x-target_point),dot(Qf,(x-target_point)))\n",
    "\n",
    "    \n",
    "def total_cost(X,U,Q = None,R = None, Qf = None):\n",
    "    \n",
    "    Q1, R1, Qf1 = linearized_cost_function_matrices() \n",
    "    Q = Q1 if Q == None else Q\n",
    "    R = R1 if R == None else R\n",
    "    Qf = Qf1 if Qf == None else Qf\n",
    "    c=0\n",
    "    #print(X.shape[0])\n",
    "    for i in range(X.shape[0]-1):\n",
    "        c+=cost(X[i],U[i],Q,R)\n",
    "    c+=end_cost(X[i],U[i],Qf)\n",
    "    return c\n",
    "\n",
    "def LQR(x_now = starting_point, relative_x=array([pi,0,0,0]), N=N, relative_u=array([0,0]),output_x=False):\n",
    "    A,B=acrobot_linearized_system(relative_x, relative_u)\n",
    "    Q, R, Qf = linearized_cost_function_matrices()\n",
    "    \n",
    "    K = our_lqr(A,B,Q,R)\n",
    "    u = zeros([N,2])\n",
    "    x = zeros([N+1,4])\n",
    "    x[0] = x_now\n",
    "    for j in range(N):\n",
    "        u[j]=relative_u + dot(-K,x[j]- relative_x)\n",
    "        x[j+1] = acrobot_next_step(x[j],u[j]) \n",
    "    if output_x:\n",
    "        return (u, x)\n",
    "    return u\n",
    "\n",
    "u=LQR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uu=u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative LQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iLQR_init():\n",
    "    A,B=acrobot_linearized_system()\n",
    "    Q, R, Qf = linearized_cost_function_matrices()\n",
    "    K = our_lqr(A,B,Q,R)\n",
    "    x = zeros([N+1,4])\n",
    "    x[0] = starting_point\n",
    "    x_reference = array([pi,0,0,0])\n",
    "    u = zeros([N,2])\n",
    "    for j in range(N):\n",
    "        u[j]=dot(-K,x[j]- x_reference)\n",
    "\n",
    "        x[j+1] = (x[j]+(dot(A,x[j]-x_reference)+dot(B,u[j]))*dt)#\n",
    "    return (u, x)\n",
    "\n",
    "# Only work for small disturbance\n",
    "def iLQR(threshold = 1e-4,loop_limit=20):\n",
    "    #generate initial u and x through regular LQR\n",
    "    u_hat, x_hat = iLQR_init()\n",
    "    step = 1\n",
    "    cost = float(\"Inf\")\n",
    "    for loop in range(loop_limit):\n",
    "        u_new = np.copy(u_hat)\n",
    "        x_new = np.copy(x_hat)\n",
    "\n",
    "        for i in range(N):\n",
    "            u_new[i] = LQR(x_now = x_new[i], relative_x=x_hat[i], N=1, relative_u=u_hat[i])\n",
    "        #for j in range(N-1):\n",
    "            x_new[i+1] = acrobot_next_step(x_new[i],u_new[i])\n",
    "        print(loop_limit)\n",
    "        \n",
    "        cost_now = total_cost(x_new,u_new)\n",
    "        print(cost_now)\n",
    "        if cost_now <= cost:\n",
    "            if cost-cost_now < threshold:\n",
    "                break\n",
    "            u_hat = u_new\n",
    "            x_hat = x_new\n",
    "            cost = cost_now\n",
    "        else:\n",
    "            break\n",
    "    print(x_new[-1])\n",
    "\n",
    "    return u_new\n",
    "\n",
    "# following Tassa 2012 paper\n",
    "def iLQR2(threshold = 1e-15,loop_limit=100):\n",
    "    #generate initial u and x through regular LQR\n",
    "    u_hat, x_hat = iLQR_init()\n",
    "    u_hat = random.normal(0,size=[N,2])#zeros([N,2])\n",
    "    x_hat = simulation(starting_point,u_hat)\n",
    "    lamb = 1\n",
    "    cost = float(\"Inf\")\n",
    "    recalculate_path = True\n",
    "    for loop in range(loop_limit):\n",
    "        if recalculate_path:\n",
    "            f_x = np.zeros((N, 4,4)) \n",
    "            f_u = np.zeros((N, 4,2)) \n",
    "            l = np.zeros((N,1))\n",
    "            l_x = np.zeros((N, 4)) \n",
    "            l_xx = np.zeros((N, 4, 4)) \n",
    "            l_u = np.zeros((N, 2))\n",
    "            l_uu = np.zeros((N, 2, 2)) \n",
    "            l_ux = np.zeros((N, 2, 4))\n",
    "\n",
    "            for t in range(N-1):\n",
    "                f_x[t] = df_ddx(x_hat[t], u_hat[t])*dt+np.identity(4)\n",
    "                f_u[t] = dfdu(x_hat[t], u_hat[t])*dt\n",
    "                l[t] = (dot(x_hat[-1]-array([pi,0,0,0]),x_hat[-1]-array([pi,0,0,0]))+dot(u_hat[t],u_hat[t]))*dt\n",
    "                l_x[t] =2*x_hat[t]*dt\n",
    "                l_xx[t] = 2*np.identity(4)*dt\n",
    "                l_u[t] =2*u_hat[t]*dt\n",
    "                l_uu[t] = 2*np.identity(2)*dt\n",
    "            l[-1] = np.sum((x_hat[-1]-array([pi,0,0,0]))**2)\n",
    "            #print(l_x[-1])\n",
    "            l_x[-1] = 2*(x_hat[-1]-array([pi,0,0,0]))\n",
    "            l_xx[-1] = 2*np.eye(4)\n",
    "            recalculate_path = False\n",
    "\n",
    "        V = l[-1].copy() \n",
    "        V_x = l_x[-1].copy() \n",
    "        V_xx = l_xx[-1].copy()\n",
    "        print(\"v:%d\"%(V))\n",
    "        k = np.zeros((N, 2)) \n",
    "        K = np.zeros((N, 2, 4)) \n",
    "        print((V_x))\n",
    "        print((V_xx))\n",
    "        \n",
    "        for t in range(N-2, -1, -1):\n",
    "\n",
    "            Q_x = l_x[t] + np.dot(f_x[t].T, V_x) \n",
    "            Q_u = l_u[t] + np.dot(f_u[t].T, V_x)\n",
    "            Q_xx = l_xx[t] + np.dot(f_x[t].T, np.dot(V_xx, f_x[t])) \n",
    "            Q_ux = l_ux[t] + np.dot(f_u[t].T, np.dot(V_xx, f_x[t]))\n",
    "            Q_uu = l_uu[t] + np.dot(f_u[t].T, np.dot(V_xx, f_u[t]))\n",
    "            Q_uu_evals, Q_uu_evecs = np.linalg.eig(Q_uu)\n",
    "            Q_uu_evals[Q_uu_evals < 0] = 0.0\n",
    "            Q_uu_evals += lamb\n",
    "            Q_uu_inv = np.dot(Q_uu_evecs, \n",
    "                    np.dot(np.diag(1.0/Q_uu_evals), Q_uu_evecs.T))\n",
    "            k[t] = -np.dot(Q_uu_inv, Q_u)\n",
    "            K[t] = -np.dot(Q_uu_inv, Q_ux)\n",
    "            V_x = Q_x - np.dot(K[t].T, np.dot(Q_uu, k[t]))\n",
    "            V_xx = Q_xx - np.dot(K[t].T, np.dot(Q_uu, K[t]))\n",
    "        u_new = np.copy(u_hat)\n",
    "        x_new = np.copy(x_hat)\n",
    "        \n",
    "        for i in range(N):\n",
    "            u_new[i] = u_hat[i] + k[i] + np.dot(K[i], x_new[i] - x_hat[i]) \n",
    "            x_new[i+1] = acrobot_next_step(x_new[i],u_new[i])\n",
    "        # evaluate the new trajectory \n",
    "        cost_now = total_cost(x_new,u_new,Q=zeros([4,4])*dt,Qf=np.eye(4),R=np.eye(2)*dt)\n",
    "        print(cost_now)\n",
    "        print(cost)\n",
    "        if cost_now <= cost:\n",
    "            lamb/=10\n",
    "            u_hat = u_new\n",
    "            x_hat = x_new\n",
    "            #print(u_hat[0:10,:])\n",
    "            recalculate_path = True\n",
    "            print(\"new path\")\n",
    "            if (cost-cost_now)/cost_now < threshold:\n",
    "                break\n",
    "            cost = cost_now\n",
    "            \n",
    "        else:\n",
    "            lamb*=10\n",
    "            \n",
    "\n",
    "    return u_hat,x_hat\n",
    "\n",
    "u,x_hat=iLQR2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrangian Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrangian Bruteforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#brute force method, not converging\n",
    "\n",
    "def lagrangian(input_array):\n",
    "    #x is x1 to xN,followed by U0 to UN-1, followed by lambda0 to lambdaN-1\n",
    "    x = np.concatenate([starting_point,input_array[:(N-1)*4]])\n",
    "    u = input_array[(N-1)*4:(N-1)*4+N]\n",
    "    lam = input_array[(N-1)*4+N:-1]\n",
    "\n",
    "    L=0\n",
    "    for i in range(N-1):\n",
    "        #current x\n",
    "        xx = x[i*4:(i+1)*4]\n",
    "        #next x\n",
    "        xx_p1 = x[(i+1)*4:(i+2)*4]\n",
    "        #difference between x+dt*dx and x_next\n",
    "        delta = xx+dt*acrobot_motion(xx,u[i])-xx_p1\n",
    "        #minimize energy\n",
    "        cost = cost_function(xx,u[i])\n",
    "        lagragian_term = lam[i]*(delta[0:1]%(2*pi))\n",
    "        L+=cost+lagragian_term\n",
    "    return L\n",
    "def lagrangian_train():\n",
    "    init = np.ones(N*4+N+N)\n",
    "    out = minimize(lagrangian,init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrangian multiplier derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad_lagrangian_trick(u):\n",
    "    # u is a vector of u0 to uN-1\n",
    "    n=len(u)//2\n",
    "    \n",
    "    u=np.reshape(u,[n,2])\n",
    "    x = zeros([n+1,4])\n",
    "    x[0]=starting_point\n",
    "    lam = zeros([n,4])\n",
    "    lam[n-1] = zeros(4)\n",
    "    dldu = zeros([n,2])\n",
    "    \n",
    "    #calculate gradient through back propagation\n",
    "    for i in range(n):\n",
    "        x[i+1]=acrobot_next_step(x[i],u[i])\n",
    "        \n",
    "    for i in reversed(range(1,n)):\n",
    "        lam[i-1]=dgdx(x[i],u[i],i,n)+dot(dfdxT(x[i],u[i]),lam[i])\n",
    "    \n",
    "    for i in range(n):\n",
    "        dldu[i]=dgdu(x[i],u[i])+dot(lam[i],dfdu(x[i],u[i]))\n",
    "    \n",
    "    return np.reshape(dldu,n*2)\n",
    "\n",
    "def lagrangian_root_train(dt,N):\n",
    "    u = zeros([N*2])#random.normal(0,size=N)\n",
    "    #print(u.shape)\n",
    "    out = root(grad_lagrangian_trick,u) \n",
    "    print(lagrangian_trick(out.x))\n",
    "    return (out,out.x.reshape([N,2]))\n",
    "\n",
    "def lagrangian_trick(u):\n",
    "    #x is x1 to xN,followed by U0 to UN-1, followed by lambda0 to lambdaN-1\n",
    "        # u is a vector of u0 to uN-1\n",
    "    n=len(u)//2\n",
    "    \n",
    "    u=np.reshape(u,[n,2])\n",
    "    x = zeros([n+1,4])\n",
    "    x[0]=starting_point\n",
    "    lam = zeros([n,4])\n",
    "    lam[n-1] = zeros(4)\n",
    "    \n",
    "    \n",
    "    #calculate gradient through back propagation\n",
    "    for i in range(n):\n",
    "        x[i+1]=acrobot_next_step(x[i],u[i])\n",
    "        \n",
    "    for i in reversed(range(1,n)):\n",
    "        lam[i-1]=dgdx(x[i],u[i],i,n)+dot(dfdxT(x[i],u[i]),lam[i])\n",
    "\n",
    "    L=0\n",
    "    U=0\n",
    "    for i in range(n):\n",
    "        #current x\n",
    "        xx = x[i]\n",
    "        #next x\n",
    "        xx_p1 = x[i+1]\n",
    "        #difference between x+dt*dx and x_next\n",
    "        delta = xx+dt*acrobot_gradient(xx,u[i])-xx_p1\n",
    "        #minimize energy\n",
    "        cost = cost_function(xx,u[i],i,n)\n",
    "        lagragian_term = dot(lam[i],delta)\n",
    "        L+=cost#+lagragian_term\n",
    "        U+= dot(u[i],u[i])\n",
    "    if print_L: print(\"L: \"+str(L)+\" U:\"+str(r/2*U))\n",
    "    costs.append(L)\n",
    "    return L\n",
    "\n",
    "def lagrangian_BFGS_train(dt,N,normal_seed=True,u=None):\n",
    "    if u == None:\n",
    "        u = random.normal(0,size=N*2) if normal_seed else zeros([N*2])\n",
    "    #print(u.shape)\n",
    "    out = minimize(lagrangian_trick,u,jac=grad_lagrangian_trick,options={\"disp\":True}) \n",
    "    return (out,out.x.reshape([N,2]))\n",
    "def lagrangian_trick_train():\n",
    "    init = np.ones(N*2)\n",
    "    out = minimize(lagrangian_trick,init)\n",
    "    return (out,out.x.reshape([N,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chebyshev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interpolate_fit(x, coef):\n",
    "    f = lambda x : sum([pow(x, y)*coef[y] for y in range(len(coef))])\n",
    "    vfunc = np.vectorize(f)\n",
    "    return vfunc(x)\n",
    "\n",
    "def interpolate_grad_fit(x, cheby_t, cheby_u):\n",
    "    # fit gradient of model relate to cheby u\n",
    "    # dL(t)dwj = lj(t) = (x-x0)/(xj-x0)....x-xk)/(xj-xk)\n",
    "    f = lambda x : array(\n",
    "        [\n",
    "            np.prod([\n",
    "                (x-xi)/(xj-xi) \n",
    "                for xi in cheby_t if xi!=xj\n",
    "            ]) \n",
    "            for xj in cheby_t\n",
    "        ]\n",
    "    )\n",
    "    return array([f(xx) for xx in x])\n",
    "    \n",
    "def chebyshev_gradient(ts,order,cheby_t,cheby_u):\n",
    "\n",
    "    #calculate u according to current chebyshev\n",
    "    u = zeros([len(ts),2])\n",
    "    cheby_u = cheby_u.reshape([order,2])\n",
    "    poly1 = np.flipud(lagrange(cheby_t,cheby_u[:,0]))\n",
    "    u[:,0] = interpolate_fit(ts, poly1)\n",
    "    poly2 = np.flipud(lagrange(cheby_t,cheby_u[:,1]))\n",
    "    u[:,1] = interpolate_fit(ts, poly2)\n",
    "    # calculate dLdw\n",
    "    dldu = grad_lagrangian_trick(u.reshape(len(ts)*2)).reshape([len(ts),2])\n",
    "    dudw1 = interpolate_grad_fit(ts, cheby_t, cheby_u[:,0])\n",
    "    dudw2 = interpolate_grad_fit(ts, cheby_t, cheby_u[:,1])\n",
    "    return array([[simps(dudw1[:,i]*dldu[:,0],ts),simps(dudw2[:,i]*dldu[:,1],ts)] for i in range(order)]).reshape(order*2)\n",
    "\n",
    "def chebyshev_cost(ts,order,cheby_t,cheby_u):\n",
    "\n",
    "    #calculate u according to current chebyshev\n",
    "    cheby_u = cheby_u.reshape([order,2])\n",
    "    poly1 = np.flipud(lagrange(cheby_t,cheby_u[:,0]))\n",
    "    poly2 = np.flipud(lagrange(cheby_t,cheby_u[:,1]))\n",
    "    u = np.concatenate([interpolate_fit(ts, poly1),interpolate_fit(ts, poly2)])\n",
    "    # calculate dLdw\n",
    "    return lagrangian_trick(u)\n",
    "\n",
    "def chebyshev_root_train(dt,N,order):\n",
    "    chebyshev = lambda n: array([cos((2*j-1)*pi/(2*n)) for j in range(1,n+1)])\n",
    "    Duration = N*dt\n",
    "    ts = np.arange(N)*dt\n",
    "    cheby_t = (chebyshev(order)+1)*Duration/2\n",
    "    cheby_u = random.normal(0,size=order*2)\n",
    "    \n",
    "    local_chebyshev_gradient = lambda cheby_u: chebyshev_gradient(ts,order,cheby_t,cheby_u)\n",
    "    out = root(local_chebyshev_gradient,cheby_u)\n",
    "    \n",
    "    #get final u array\n",
    "    cheby_u = out.x.reshape([order,2])\n",
    "    u = zeros([N,2])\n",
    "    poly1 = np.flipud(lagrange(cheby_t,cheby_u[:,0]))\n",
    "    u[:,0] = interpolate_fit(ts, poly1)\n",
    "    poly2 = np.flipud(lagrange(cheby_t,cheby_u[:,1]))\n",
    "    u[:,1] = interpolate_fit(ts, poly2)\n",
    "    return (out,u)\n",
    "\n",
    "def chebyshev_BFGS_train(dt,N,order):\n",
    "    chebyshev = lambda n: array([cos((2*j-1)*pi/(2*n)) for j in range(1,n+1)])\n",
    "    Duration = N*dt\n",
    "    ts = np.arange(N)*dt\n",
    "    cheby_t = (chebyshev(order)+1)*Duration/2\n",
    "    cheby_u = random.normal(0,size=order*2)\n",
    "    \n",
    "    local_chebyshev_gradient = lambda cheby_u: chebyshev_gradient(ts,order,cheby_t,cheby_u)\n",
    "    local_chebyshev_cost = lambda cheby_u: chebyshev_cost(ts,order,cheby_t,cheby_u)\n",
    "    out = minimize(local_chebyshev_cost,cheby_u,jac=local_chebyshev_gradient)\n",
    "    \n",
    "    #get final u array\n",
    "    cheby_u = out.x.reshape([order,2])\n",
    "    u = zeros([N,2])\n",
    "    poly1 = np.flipud(lagrange(cheby_t,cheby_u[:,0]))\n",
    "    u[:,0] = interpolate_fit(ts, poly1)\n",
    "    poly2 = np.flipud(lagrange(cheby_t,cheby_u[:,1]))\n",
    "    u[:,1] = interpolate_fit(ts, poly2)\n",
    "    return (out,u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reset costs\n",
    "costs=[]\n",
    "#out = chebyshev_root_train(dt,N,3) \n",
    "#out = lagrangian_root_train(dt,N)\n",
    "out = lagrangian_BFGS_train(dt,N)\n",
    "#out = chebyshev_BFGS_train(dt,N,20) \n",
    "#out = lagrangian_trick_train()\n",
    "u = out[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#u = zeros(N)\n",
    "def simulation(starting_point,u):\n",
    "    x = np.zeros((N+1, 4))\n",
    "    \n",
    "    x[0] = starting_point\n",
    "    for i in range(N-1):\n",
    "        x[i+1] = acrobot_next_step(x[i], u[i])\n",
    "        x[i+1][0]=x[i+1][0]%(2*pi)\n",
    "        x[i+1][1]=x[i+1][1]%(2*pi)\n",
    "    return x\n",
    "\n",
    "x = simulation(starting_point,u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def anima(x):\n",
    "    # First set up the figure, the axis, and the plot element we want to animate\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    ax.set_xlim(( -2.2, 2.2))\n",
    "    ax.set_ylim((-2.2, 2.2))\n",
    "\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "\n",
    "    # initialization function: plot the background of each frame\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        return (line,)\n",
    "\n",
    "    # animation function. This is called sequentially\n",
    "    def animate(k):\n",
    "        x1 = cos(x[k,0]-pi/2);\n",
    "        y1 = sin(x[k,0]-pi/2);\n",
    "        x2 = x1 + cos(x[k,0]+x[k,1]-pi/2);\n",
    "        y2 = y1 + sin(x[k,0]+x[k,1]-pi/2);\n",
    "\n",
    "        xs = [0, x1, x2]\n",
    "        ys = [0, y1, y2]\n",
    "        line.set_data(xs, ys)\n",
    "        return (line,)\n",
    "\n",
    "    # call the animator. blit=True means only re-draw the parts that have changed.\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=N, interval=20, blit=True)\n",
    "    HTML(anim.to_html5_video())\n",
    "anima(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot(title):\n",
    "    ts = np.arange(N)*dt\n",
    "    plt.plot(ts,x[:,0][:N],label=\"q1\")\n",
    "    plt.plot(ts,x[:,1][:N],label=\"q2\")\n",
    "    plt.plot(ts,ones(N)*pi,\"--\",label=\"q1 optimal\")\n",
    "    plt.plot(ts,zeros(N),\"--\",label=\"q2 optimal\")\n",
    "    plt.plot(ts,u[:,0],label=\"u1\")\n",
    "    plt.plot(ts,u[:,1],label=\"u2\")\n",
    "    plt.legend()\n",
    "    plt.ylim([-2*pi,2*pi])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "plot(\"current model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chebyshev plot\n",
    "conditions = [array([0.01+pi,0,0,0]),array([0.1,0,0,0])]\n",
    "durations = [1,2]\n",
    "full_actuated = [\"full\",\"under\"]\n",
    "fig, axes = plt.subplots(len(conditions), figsize=(10,10))\n",
    "for i in range(len(conditions)):\n",
    "        Duration = durations[i]\n",
    "        starting_point = conditions[i]\n",
    "        global_B = global_B_dict[full_actuated[i]]\n",
    "        N = int(Duration*FPS)\n",
    "        ts = np.arange(N)*dt\n",
    "        u=chebyshev_BFGS_train(dt,N,13)[1]\n",
    "        x = np.zeros((N, 4))\n",
    "        x[0] = starting_point\n",
    "        x = simulation(starting_point,u)\n",
    "        \n",
    "        axes[i].set_ylim([-2*pi,2*pi])\n",
    "        axes[i].plot(ts,x[:,0][:N],label=\"q1\")\n",
    "        axes[i].plot(ts,x[:,1][:N],label=\"q2\")\n",
    "        axes[i].plot(ts,ones(N)*pi,\"--\",label=\"q1 optimal\")\n",
    "        axes[i].plot(ts,zeros(N),\"--\",label=\"q2 optimal\")\n",
    "        axes[i].plot(ts,u,label=\"u\")\n",
    "        axes[i].legend()\n",
    "        axes[i].set_title(\"Chebyshev BFGS, \"+full_actuated[i]+\" actuated, Start \"+str(starting_point[0])+\", Time \"+str(Duration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lagrangian plot\n",
    "conditions = [array([0.01+pi,0,0,0]),array([0.1,0,0,0])]\n",
    "durations = [1,2]\n",
    "full_actuated = [\"full\",\"under\"]\n",
    "fig, axes = plt.subplots(len(conditions), figsize=(10,10))\n",
    "for i in range(len(conditions)):\n",
    "        Duration = durations[i]\n",
    "        starting_point = conditions[i]\n",
    "        global_B = global_B_dict[full_actuated[i]]\n",
    "        N = int(Duration*FPS)\n",
    "        ts = np.arange(N)*dt\n",
    "        u=lagrangian_BFGS_train(dt,N)[1]\n",
    "        x = np.zeros((N, 4))\n",
    "        x[0] = starting_point\n",
    "        x = simulation(starting_point,u)\n",
    "        \n",
    "        axes[i].set_ylim([-2*pi,2*pi])\n",
    "        axes[i].plot(ts,x[:,0][:N],label=\"q1\")\n",
    "        axes[i].plot(ts,x[:,1][:N],label=\"q2\")\n",
    "        axes[i].plot(ts,ones(N)*pi,\"--\",label=\"q1 optimal\")\n",
    "        axes[i].plot(ts,zeros(N),\"--\",label=\"q2 optimal\")\n",
    "        axes[i].plot(ts,u,label=\"u\")\n",
    "        axes[i].legend()\n",
    "        axes[i].set_title(\"Lagrangian BFGS, \"+full_actuated[i]+\" actuated, Start \"+str(starting_point[0])+\", Time \"+str(Duration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# No control plot\n",
    "conditions = [array([0.01+pi,0,0,0]),array([0.1,0,0,0])]\n",
    "durations = [1,2]\n",
    "full_actuated = [\"full\",\"under\"]\n",
    "fig, axes = plt.subplots(len(conditions), figsize=(10,10))\n",
    "for i in range(len(conditions)):\n",
    "        Duration = durations[i]\n",
    "        starting_point = conditions[i]\n",
    "        global_B = global_B_dict[full_actuated[i]]\n",
    "        N = int(Duration*FPS)\n",
    "        ts = np.arange(N)*dt\n",
    "        u=np.zeros([N,2])\n",
    "        x = np.zeros((N, 4))\n",
    "        x[0] = starting_point\n",
    "        x = simulation(starting_point,u)\n",
    "        \n",
    "        axes[i].set_ylim([-2*pi,2*pi])\n",
    "        axes[i].plot(ts,x[:,0][:N],label=\"q1\")\n",
    "        axes[i].plot(ts,x[:,1][:N],label=\"q2\")\n",
    "        axes[i].plot(ts,ones(N)*pi,\"--\",label=\"q1 optimal\")\n",
    "        axes[i].plot(ts,zeros(N),\"--\",label=\"q2 optimal\")\n",
    "        axes[i].plot(ts,u,label=\"u\")\n",
    "        axes[i].legend()\n",
    "        axes[i].set_title(\"No Control, \"+full_actuated[i]+\" actuated, Start \"+str(starting_point[0])+\", Time \"+str(Duration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LQR plot\n",
    "Duration = 5\n",
    "starting_point = array([0,0,0,0])\n",
    "global_B = array([[1,0],[0,1]])#full actuated\n",
    "#--------\n",
    "N = int(Duration*FPS)\n",
    "ts = np.arange(N)*dt\n",
    "\n",
    "u=LQR(x_now = starting_point, N=N)\n",
    "x[0] = starting_point\n",
    "x = simulation(starting_point,u)\n",
    "plot(\"LQR full actuated, Start Point \"+str(starting_point[0])+\", Time \"+str(Duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cost function visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = 100\n",
    "contour_points = np.zeros([100,100])\n",
    "contour_x = np.linspace(0,2*pi,100)\n",
    "contour_y = np.linspace(0,2*pi,100)\n",
    "for x in range(grid):\n",
    "    for y in range(grid):\n",
    "        xx=contour_x[x]\n",
    "        yy=contour_y[y]\n",
    "        contour_points[y][x]=cost_function([xx,yy],[0,0],0,7)\n",
    "plt.figure(figsize=(6, 6))\n",
    "CS=plt.contour(contour_x,contour_y,contour_points,20)\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "plt.title(\"Cost Distribution\")\n",
    "plt.xlabel(\"x0\")\n",
    "plt.ylabel(\"x1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Visualization of Lagrangian methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.log(costs))\n",
    "plt.title(\"log costs over time, full actuated BFGS\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"log(L)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
